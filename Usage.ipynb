{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e3d123e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from kadapter.configurations import *\n",
    "from kadapter.model import *\n",
    "\n",
    "from transformers import RobertaModel\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5e6bd0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING:root:Config of the K-Adapter Head is overwritten by shared Head config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAdapterConfig {\n",
      "  \"_commit_hash\": null,\n",
      "  \"adapters\": [\n",
      "    {\n",
      "      \"_name_or_path\": \"\",\n",
      "      \"add_cross_attention\": false,\n",
      "      \"architectures\": null,\n",
      "      \"attention_probs_dropout_prob\": 0.1,\n",
      "      \"bad_words_ids\": null,\n",
      "      \"bos_token_id\": null,\n",
      "      \"chunk_size_feed_forward\": 0,\n",
      "      \"classifier_dropout\": null,\n",
      "      \"cross_attention_hidden_size\": null,\n",
      "      \"decoder_start_token_id\": null,\n",
      "      \"diversity_penalty\": 0.0,\n",
      "      \"do_sample\": false,\n",
      "      \"early_stopping\": false,\n",
      "      \"encoder_no_repeat_ngram_size\": 0,\n",
      "      \"eos_token_id\": null,\n",
      "      \"exponential_decay_length_penalty\": null,\n",
      "      \"finetuning_task\": null,\n",
      "      \"forced_bos_token_id\": null,\n",
      "      \"forced_eos_token_id\": null,\n",
      "      \"freeze\": false,\n",
      "      \"hidden_act\": \"gelu\",\n",
      "      \"hidden_dimension\": 120,\n",
      "      \"hidden_dropout_prob\": 0.1,\n",
      "      \"hidden_size\": 768,\n",
      "      \"id2label\": {\n",
      "        \"0\": \"LABEL_0\",\n",
      "        \"1\": \"LABEL_1\"\n",
      "      },\n",
      "      \"initializer_range\": 0.0002,\n",
      "      \"injection_layers\": [\n",
      "        0,\n",
      "        11\n",
      "      ],\n",
      "      \"intermediate_size\": 3072,\n",
      "      \"is_decoder\": false,\n",
      "      \"is_encoder_decoder\": false,\n",
      "      \"label2id\": {\n",
      "        \"LABEL_0\": 0,\n",
      "        \"LABEL_1\": 1\n",
      "      },\n",
      "      \"layer_norm_eps\": 1e-12,\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 20,\n",
      "      \"max_position_embeddings\": 512,\n",
      "      \"min_length\": 0,\n",
      "      \"model_name\": \"fac-adapter\",\n",
      "      \"model_type\": \"bert\",\n",
      "      \"no_repeat_ngram_size\": 0,\n",
      "      \"num_attention_heads\": 12,\n",
      "      \"num_beam_groups\": 1,\n",
      "      \"num_beams\": 1,\n",
      "      \"num_hidden_layers\": 2,\n",
      "      \"num_return_sequences\": 1,\n",
      "      \"output_attentions\": false,\n",
      "      \"output_hidden_states\": false,\n",
      "      \"output_scores\": false,\n",
      "      \"pad_token_id\": 0,\n",
      "      \"position_embedding_type\": \"absolute\",\n",
      "      \"prefix\": null,\n",
      "      \"problem_type\": null,\n",
      "      \"pruned_heads\": {},\n",
      "      \"remove_invalid_values\": false,\n",
      "      \"repetition_penalty\": 1.0,\n",
      "      \"return_dict\": true,\n",
      "      \"return_dict_in_generate\": false,\n",
      "      \"sep_token_id\": null,\n",
      "      \"skip_layers\": 3,\n",
      "      \"task_specific_params\": null,\n",
      "      \"temperature\": 1.0,\n",
      "      \"tf_legacy_loss\": false,\n",
      "      \"tie_encoder_decoder\": false,\n",
      "      \"tie_word_embeddings\": true,\n",
      "      \"tokenizer_class\": null,\n",
      "      \"top_k\": 50,\n",
      "      \"top_p\": 1.0,\n",
      "      \"torch_dtype\": null,\n",
      "      \"torchscript\": false,\n",
      "      \"transformers_version\": \"4.22.2\",\n",
      "      \"type_vocab_size\": 2,\n",
      "      \"typical_p\": 1.0,\n",
      "      \"use_bfloat16\": false,\n",
      "      \"use_cache\": true,\n",
      "      \"vocab_size\": 30522\n",
      "    }\n",
      "  ],\n",
      "  \"basemodel\": {\n",
      "    \"_name_or_path\": \"roberta-base\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "      \"RobertaForMaskedLM\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": 0,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"classifier_dropout\": null,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": 2,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-05,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 514,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"roberta\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": true,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 1,\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.22.2\",\n",
      "    \"type_vocab_size\": 1,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 50265\n",
      "  },\n",
      "  \"freeze_basemodel\": false,\n",
      "  \"head\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": null,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": null,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"head_type\": \"kadapter-head-sum\",\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"kadapter-head-sum\",\n",
      "    \"n_adapters\": 1,\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": null,\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.22.2\",\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false\n",
      "  },\n",
      "  \"model_type\": \"kadapter\",\n",
      "  \"transformers_version\": null\n",
      "}\n",
      " RobertaModel(\n",
      "  (embeddings): RobertaEmbeddings(\n",
      "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "    (token_type_embeddings): Embedding(1, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): RobertaEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): RobertaPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ") None None\n"
     ]
    }
   ],
   "source": [
    "adapter_config_1 = AdapterConfig('fac-adapter', hidden_dimension=120)\n",
    "head_config = KAdapterHeadConfig(head_type='kadapter-head-sum')\n",
    "basemodel = RobertaModel.from_pretrained('roberta-base', output_hidden_states=True)\n",
    "\n",
    "# Load architecture from configs\n",
    "kadapter_config = KAdapterConfig.from_adapter_configs(basemodel.config, [adapter_config_1], head_config)\n",
    "model = KAdapterModel(config=kadapter_config, basemodel=basemodel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59ca3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dbac283c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.0510,  0.0778,  0.0396,  0.0291, -0.0233,  0.0533, -0.0118,  0.0712,\n",
      "         0.0342, -0.0875,  0.0110, -0.0825,  0.0620, -0.0155,  0.0883, -0.0500,\n",
      "         0.0189, -0.0691, -0.0552, -0.0487,  0.0108, -0.0077, -0.0093, -0.0333,\n",
      "         0.0829, -0.0586, -0.0036, -0.0120, -0.0626,  0.0636, -0.0340, -0.0117,\n",
      "        -0.0383, -0.0744, -0.0056,  0.0178,  0.0691, -0.0155,  0.0898, -0.0885,\n",
      "         0.0557, -0.0342, -0.0868, -0.0164,  0.0423, -0.0412, -0.0640, -0.0780,\n",
      "        -0.0462, -0.0028, -0.0438, -0.0434, -0.0538, -0.0353, -0.0338,  0.0727,\n",
      "        -0.0445,  0.0838,  0.0234,  0.0605,  0.0267,  0.0499,  0.0589, -0.0637,\n",
      "        -0.0367, -0.0746,  0.0724, -0.0644,  0.0211,  0.0348, -0.0574,  0.0534,\n",
      "         0.0085, -0.0240, -0.0862, -0.0833,  0.0802, -0.0122, -0.0482, -0.0234,\n",
      "         0.0220, -0.0590,  0.0059,  0.0172,  0.0688,  0.0612, -0.0113, -0.0223,\n",
      "         0.0124,  0.0509,  0.0555,  0.0251, -0.0220,  0.0023,  0.0885,  0.0252,\n",
      "         0.0336,  0.0757, -0.0304, -0.0526,  0.0757,  0.0453,  0.0262, -0.0338,\n",
      "        -0.0185, -0.0886,  0.0008,  0.0277,  0.0592, -0.0741,  0.0702,  0.0047,\n",
      "         0.0080,  0.0051, -0.0684, -0.0464, -0.0169, -0.0047,  0.0421, -0.0802,\n",
      "         0.0060,  0.0890,  0.0380, -0.0165, -0.0294, -0.0132, -0.0350, -0.0350,\n",
      "         0.0649,  0.0223,  0.0731,  0.0014, -0.0121,  0.0490, -0.0278, -0.0714,\n",
      "        -0.0488, -0.0413,  0.0483,  0.0684,  0.0703,  0.0103,  0.0636,  0.0907,\n",
      "         0.0487,  0.0509, -0.0092,  0.0458,  0.0837, -0.0648, -0.0467,  0.0145,\n",
      "        -0.0531,  0.0048,  0.0031,  0.0747,  0.0664,  0.0471, -0.0125,  0.0891,\n",
      "         0.0636,  0.0798, -0.0129, -0.0733,  0.0339, -0.0479, -0.0370,  0.0418,\n",
      "        -0.0546, -0.0566, -0.0757, -0.0811,  0.0194,  0.0148, -0.0427, -0.0644,\n",
      "        -0.0262,  0.0783,  0.0498,  0.0178, -0.0762,  0.0755,  0.0222,  0.0187,\n",
      "         0.0317,  0.0668,  0.0450, -0.0759,  0.0326, -0.0670, -0.0687,  0.0623,\n",
      "         0.0109,  0.0471, -0.0384, -0.0332, -0.0132, -0.0415, -0.0515, -0.0810,\n",
      "        -0.0753, -0.0720,  0.0847,  0.0198, -0.0466,  0.0775, -0.0828, -0.0157,\n",
      "        -0.0834,  0.0689, -0.0913,  0.0708, -0.0684,  0.0757,  0.0599,  0.0246,\n",
      "        -0.0243, -0.0319, -0.0384, -0.0578,  0.0369,  0.0128, -0.0840, -0.0084,\n",
      "        -0.0402, -0.0162, -0.0032,  0.0793, -0.0194,  0.0176,  0.0647,  0.0355,\n",
      "         0.0242, -0.0411,  0.0313, -0.0139,  0.0497, -0.0763, -0.0125,  0.0837,\n",
      "        -0.0574,  0.0578, -0.0786, -0.0307, -0.0143,  0.0102, -0.0195,  0.0335,\n",
      "         0.0171, -0.0345,  0.0075, -0.0465, -0.0891, -0.0518, -0.0377, -0.0136,\n",
      "        -0.0359, -0.0898,  0.0783,  0.0013, -0.0744,  0.0562, -0.0908,  0.0746,\n",
      "        -0.0752,  0.0395, -0.0087,  0.0495,  0.0044,  0.0481,  0.0289,  0.0074,\n",
      "        -0.0909,  0.0831,  0.0115,  0.0436,  0.0181,  0.0755,  0.0119, -0.0024,\n",
      "        -0.0481, -0.0197, -0.0028, -0.0163,  0.0884,  0.0404, -0.0265, -0.0891,\n",
      "        -0.0509, -0.0421,  0.0559, -0.0162, -0.0411,  0.0880,  0.0358, -0.0382,\n",
      "         0.0401, -0.0144, -0.0454,  0.0888, -0.0709,  0.0870, -0.0798,  0.0293,\n",
      "        -0.0235, -0.0516, -0.0850, -0.0692,  0.0610,  0.0620,  0.0786, -0.0671,\n",
      "        -0.0356,  0.0558, -0.0183, -0.0463, -0.0451, -0.0142,  0.0224, -0.0867,\n",
      "         0.0357,  0.0381, -0.0088,  0.0322,  0.0502,  0.0672,  0.0029, -0.0232,\n",
      "         0.0382,  0.0314,  0.0040,  0.0654, -0.0870, -0.0214, -0.0721, -0.0185,\n",
      "        -0.0616,  0.0161, -0.0554,  0.0206,  0.0762,  0.0776,  0.0017, -0.0239,\n",
      "         0.0884, -0.0697,  0.0029,  0.0238,  0.0385,  0.0016,  0.0206,  0.0350,\n",
      "        -0.0051,  0.0794,  0.0333,  0.0471,  0.0837,  0.0448,  0.0435, -0.0797,\n",
      "        -0.0415,  0.0148, -0.0299,  0.0337, -0.0303,  0.0165, -0.0540, -0.0642,\n",
      "         0.0720,  0.0011, -0.0145,  0.0007,  0.0042, -0.0607,  0.0435,  0.0596,\n",
      "         0.0336,  0.0223,  0.0534, -0.0019,  0.0211, -0.0288, -0.0029, -0.0839,\n",
      "         0.0697,  0.0299, -0.0414, -0.0425,  0.0231,  0.0885,  0.0129,  0.0195,\n",
      "         0.0410, -0.0627, -0.0658, -0.0453, -0.0828,  0.0178,  0.0369,  0.0868,\n",
      "        -0.0827, -0.0048, -0.0903,  0.0641, -0.0458, -0.0844,  0.0207, -0.0857,\n",
      "         0.0036, -0.0367, -0.0404,  0.0615, -0.0452, -0.0148, -0.0444, -0.0235,\n",
      "        -0.0284,  0.0625,  0.0462, -0.0537, -0.0043,  0.0698,  0.0056,  0.0105,\n",
      "         0.0850, -0.0864, -0.0743, -0.0719,  0.0305, -0.0805,  0.0012, -0.0483,\n",
      "        -0.0594, -0.0800,  0.0147, -0.0096,  0.0215,  0.0276,  0.0746,  0.0522,\n",
      "        -0.0909, -0.0672,  0.0650, -0.0907,  0.0336,  0.0731,  0.0615, -0.0547,\n",
      "        -0.0747,  0.0270, -0.0550,  0.0655,  0.0073, -0.0691, -0.0102,  0.0730,\n",
      "         0.0151,  0.0129,  0.0088, -0.0319, -0.0276, -0.0027, -0.0115,  0.0221,\n",
      "         0.0798,  0.0185, -0.0167,  0.0108,  0.0688, -0.0807, -0.0081, -0.0211,\n",
      "         0.0286,  0.0589, -0.0592,  0.0874,  0.0128, -0.0014,  0.0822, -0.0114,\n",
      "         0.0069,  0.0574,  0.0620,  0.0713, -0.0707,  0.0057,  0.0720, -0.0811,\n",
      "        -0.0716,  0.0651,  0.0603,  0.0048, -0.0349, -0.0176, -0.0163,  0.0181,\n",
      "        -0.0121, -0.0733,  0.0652,  0.0064,  0.0754,  0.0393,  0.0674,  0.0517,\n",
      "        -0.0352,  0.0162,  0.0423, -0.0584, -0.0253, -0.0615,  0.0296, -0.0447,\n",
      "        -0.0542, -0.0209,  0.0783, -0.0558, -0.0622, -0.0236, -0.0128,  0.0304,\n",
      "         0.0288,  0.0796, -0.0669, -0.0612,  0.0261,  0.0309,  0.0798, -0.0036,\n",
      "         0.0842,  0.0220,  0.0454, -0.0592, -0.0022,  0.0736,  0.0491, -0.0670,\n",
      "         0.0722,  0.0286,  0.0279, -0.0279, -0.0224,  0.0271,  0.0823,  0.0655,\n",
      "        -0.0676,  0.0384, -0.0349, -0.0762, -0.0485,  0.0438,  0.0889,  0.0438,\n",
      "        -0.0297, -0.0100,  0.0193, -0.0073, -0.0748, -0.0546,  0.0123,  0.0630,\n",
      "         0.0557,  0.0585,  0.0390, -0.0720, -0.0495, -0.0147, -0.0466, -0.0397,\n",
      "        -0.0549, -0.0036, -0.0155, -0.0215, -0.0065, -0.0257, -0.0660,  0.0813,\n",
      "         0.0858,  0.0691,  0.0356,  0.0274,  0.0101, -0.0341,  0.0845,  0.0282,\n",
      "         0.0373, -0.0908,  0.0471, -0.0833, -0.0650,  0.0498,  0.0840,  0.0422,\n",
      "        -0.0260, -0.0509,  0.0257,  0.0324, -0.0110,  0.0085,  0.0684,  0.0912,\n",
      "        -0.0585, -0.0204,  0.0139, -0.0800, -0.0798,  0.0653, -0.0481,  0.0696,\n",
      "        -0.0691, -0.0641,  0.0488,  0.0699,  0.0776, -0.0326,  0.0065,  0.0314,\n",
      "        -0.0117, -0.0856,  0.0089, -0.0780,  0.0226,  0.0841, -0.0255,  0.0062,\n",
      "        -0.0811, -0.0816,  0.0679,  0.0641, -0.0026, -0.0773, -0.0045,  0.0024,\n",
      "        -0.0369, -0.0507,  0.0086,  0.0187,  0.0167,  0.0102,  0.0528, -0.0157,\n",
      "        -0.0561,  0.0395,  0.0843, -0.0353,  0.0782, -0.0831, -0.0303,  0.0619,\n",
      "         0.0092,  0.0683, -0.0737, -0.0650, -0.0107,  0.0699, -0.0766, -0.0619,\n",
      "        -0.0159,  0.0178, -0.0658,  0.0752, -0.0534,  0.0191, -0.0440, -0.0463,\n",
      "        -0.0444,  0.0702,  0.0099,  0.0128, -0.0094,  0.0456, -0.0355,  0.0173,\n",
      "         0.0195,  0.0337, -0.0519,  0.0550,  0.0490,  0.0305,  0.0624,  0.0665,\n",
      "         0.0289,  0.0494,  0.0149,  0.0447,  0.0424,  0.0345, -0.0747,  0.0270,\n",
      "        -0.0838,  0.0534, -0.0089, -0.0407,  0.0511,  0.0322,  0.0072, -0.0680,\n",
      "        -0.0482,  0.0704,  0.0789, -0.0183, -0.0286,  0.0768, -0.0864,  0.0550,\n",
      "        -0.0204, -0.0432,  0.0853,  0.0541, -0.0077,  0.0809,  0.0391,  0.0862,\n",
      "        -0.0818,  0.0102,  0.0688, -0.0753, -0.0721, -0.0481, -0.0246, -0.0181,\n",
      "        -0.0815, -0.0564, -0.0400,  0.0837, -0.0477,  0.0276,  0.0633, -0.0115,\n",
      "        -0.0242,  0.0399, -0.0226,  0.0422, -0.0494,  0.0676, -0.0279,  0.0503,\n",
      "        -0.0028,  0.0374, -0.0026,  0.0712, -0.0836, -0.0613, -0.0107,  0.0822,\n",
      "        -0.0355, -0.0160,  0.0753,  0.0239,  0.0668,  0.0388,  0.0118,  0.0075,\n",
      "         0.0688, -0.0596,  0.0654, -0.0735, -0.0293,  0.0530,  0.0780, -0.0300,\n",
      "         0.0302, -0.0897, -0.0084,  0.0760,  0.0815,  0.0618, -0.0400, -0.0727],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.zeros(1,25, dtype=int)\n",
    "\n",
    "# 0.0510 0.0778\n",
    "for params in model.parameters():\n",
    "    continue\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fae338db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('save/kadapter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9fa7865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAdapterConfig {\n",
      "  \"_commit_hash\": null,\n",
      "  \"_name_or_path\": \"save/kadapter\",\n",
      "  \"adapters\": [\n",
      "    {\n",
      "      \"_name_or_path\": \"\",\n",
      "      \"add_cross_attention\": false,\n",
      "      \"architectures\": null,\n",
      "      \"attention_probs_dropout_prob\": 0.1,\n",
      "      \"bad_words_ids\": null,\n",
      "      \"bos_token_id\": null,\n",
      "      \"chunk_size_feed_forward\": 0,\n",
      "      \"classifier_dropout\": null,\n",
      "      \"cross_attention_hidden_size\": null,\n",
      "      \"decoder_start_token_id\": null,\n",
      "      \"diversity_penalty\": 0.0,\n",
      "      \"do_sample\": false,\n",
      "      \"early_stopping\": false,\n",
      "      \"encoder_no_repeat_ngram_size\": 0,\n",
      "      \"eos_token_id\": null,\n",
      "      \"exponential_decay_length_penalty\": null,\n",
      "      \"finetuning_task\": null,\n",
      "      \"forced_bos_token_id\": null,\n",
      "      \"forced_eos_token_id\": null,\n",
      "      \"freeze\": false,\n",
      "      \"hidden_act\": \"gelu\",\n",
      "      \"hidden_dimension\": 120,\n",
      "      \"hidden_dropout_prob\": 0.1,\n",
      "      \"hidden_size\": 768,\n",
      "      \"id2label\": {\n",
      "        \"0\": \"LABEL_0\",\n",
      "        \"1\": \"LABEL_1\"\n",
      "      },\n",
      "      \"initializer_range\": 0.0002,\n",
      "      \"injection_layers\": [\n",
      "        0,\n",
      "        11\n",
      "      ],\n",
      "      \"intermediate_size\": 3072,\n",
      "      \"is_decoder\": false,\n",
      "      \"is_encoder_decoder\": false,\n",
      "      \"label2id\": {\n",
      "        \"LABEL_0\": 0,\n",
      "        \"LABEL_1\": 1\n",
      "      },\n",
      "      \"layer_norm_eps\": 1e-12,\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 20,\n",
      "      \"max_position_embeddings\": 512,\n",
      "      \"min_length\": 0,\n",
      "      \"model_name\": \"fac-adapter\",\n",
      "      \"model_type\": \"bert\",\n",
      "      \"no_repeat_ngram_size\": 0,\n",
      "      \"num_attention_heads\": 12,\n",
      "      \"num_beam_groups\": 1,\n",
      "      \"num_beams\": 1,\n",
      "      \"num_hidden_layers\": 2,\n",
      "      \"num_return_sequences\": 1,\n",
      "      \"output_attentions\": false,\n",
      "      \"output_hidden_states\": false,\n",
      "      \"output_scores\": false,\n",
      "      \"pad_token_id\": 0,\n",
      "      \"position_embedding_type\": \"absolute\",\n",
      "      \"prefix\": null,\n",
      "      \"problem_type\": null,\n",
      "      \"pruned_heads\": {},\n",
      "      \"remove_invalid_values\": false,\n",
      "      \"repetition_penalty\": 1.0,\n",
      "      \"return_dict\": true,\n",
      "      \"return_dict_in_generate\": false,\n",
      "      \"sep_token_id\": null,\n",
      "      \"skip_layers\": 3,\n",
      "      \"task_specific_params\": null,\n",
      "      \"temperature\": 1.0,\n",
      "      \"tf_legacy_loss\": false,\n",
      "      \"tie_encoder_decoder\": false,\n",
      "      \"tie_word_embeddings\": true,\n",
      "      \"tokenizer_class\": null,\n",
      "      \"top_k\": 50,\n",
      "      \"top_p\": 1.0,\n",
      "      \"torch_dtype\": null,\n",
      "      \"torchscript\": false,\n",
      "      \"transformers_version\": \"4.22.2\",\n",
      "      \"type_vocab_size\": 2,\n",
      "      \"typical_p\": 1.0,\n",
      "      \"use_bfloat16\": false,\n",
      "      \"use_cache\": true,\n",
      "      \"vocab_size\": 30522\n",
      "    }\n",
      "  ],\n",
      "  \"architectures\": [\n",
      "    \"KAdapterModel\"\n",
      "  ],\n",
      "  \"basemodel\": {\n",
      "    \"_name_or_path\": \"roberta-base\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "      \"RobertaForMaskedLM\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": 0,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"classifier_dropout\": null,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": 2,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-05,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 514,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"roberta\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": true,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 1,\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.22.2\",\n",
      "    \"type_vocab_size\": 1,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 50265\n",
      "  },\n",
      "  \"freeze_basemodel\": false,\n",
      "  \"head\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": null,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": null,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"head_type\": \"kadapter-head-sum\",\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"kadapter-head-sum\",\n",
      "    \"n_adapters\": 1,\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": null,\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.22.2\",\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false\n",
      "  },\n",
      "  \"model_type\": \"kadapter\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": null\n",
      "}\n",
      " None None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Config of the K-Adapter Head is overwritten by shared Head config\n"
     ]
    }
   ],
   "source": [
    "model = KAdapterModel.from_pretrained('save/kadapter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7e10a4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"adapters\": [],\\n  \"head\": null,\\n  \"transformers_version\": \"4.22.2\"\\n}\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model = KAdapterModel.from_adapters_pretrained(['fac-adapter-roberta-base', \n",
    "                                                           'lin-adapter-roberta-base'], \n",
    "                                                          'kadapter-head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5e981ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Saving the model, including its configuration\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkadapter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# loading model and config from pretrained folder\u001b[39;00m\n\u001b[1;32m      5\u001b[0m encoder_decoder_config \u001b[38;5;241m=\u001b[39m EncoderDecoderConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkadapter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/app/.venv/lib/python3.8/site-packages/transformers/modeling_utils.py:1532\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m model_to_save \u001b[38;5;241m=\u001b[39m unwrap_model(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;66;03m# save the string version of dtype to the config, e.g. convert torch.float32 => \"float32\"\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# we currently don't use this setting automatically, but may start to use with v5\u001b[39;00m\n\u001b[0;32m-> 1532\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43mget_parameter_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_save\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1533\u001b[0m model_to_save\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtorch_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(dtype)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;66;03m# Attach architecture to the config\u001b[39;00m\n",
      "File \u001b[0;32m/app/.venv/lib/python3.8/site-packages/transformers/modeling_utils.py:197\u001b[0m, in \u001b[0;36mget_parameter_dtype\u001b[0;34m(parameter)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# fallback to the last dtype\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdtype\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "# loading model and config from pretrained folder\n",
    "encoder_decoder_config = EncoderDecoderConfig.from_pretrained(\"save/kadapter\")\n",
    "model = EncoderDecoderModel.from_pretrained(\"kadapter\", config=encoder_decoder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e122818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
