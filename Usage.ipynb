{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc5f511",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaModel\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Load the model, pretrain it, etc ...\n",
    "\"\"\"\n",
    "basemodel = RobertaModel.from_pretrained('roberta-base', output_hidden_states=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3899dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kadapter import KAdapter\n",
    "from config import AdapterConfig\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Load the Adapter.\n",
    "The basemodel is frozen by default.\n",
    "The adapters can be pretrained by freezing them one by one and training the unfreezed adapter.\n",
    "\"\"\"\n",
    "adapter = KAdapter(basemodel, AdapterConfig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda2852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
