{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# K-Adapter\n",
    "## A standard workflow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d123e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kadapter.configurations import AdapterConfig, KAdapterSumHeadConfig, KAdapterConcatHeadConfig, KAdapterConfig\n",
    "from kadapter.model import KAdapterModel\n",
    "\n",
    "from transformers import RobertaModel, AutoModel, PretrainedConfig\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load an architecture of a single adapter and an arbitrary head from configurations (In case of one adapter, the heads are identical).\n",
    "Also load a pretrained basemodel (in our case roberta-base) to inject the K-Adapter into.\n",
    "As known from the Huggingface-Framework, the configurations can be changed in-place."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6bd0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fac_adapter_config = AdapterConfig('fac-adapter', hidden_dimension=768)\n",
    "head_config = KAdapterSumHeadConfig()\n",
    "\n",
    "basemodel = RobertaModel.from_pretrained('roberta-base', output_hidden_states=True)\n",
    "\n",
    "kadapter_config = KAdapterConfig.from_adapter_configs(\n",
    "    basemodel=basemodel.config, \n",
    "    adapters=[fac_adapter_config], \n",
    "    head=head_config,\n",
    "    freeze_basemodel=True  # in order to pretrain the adapter\n",
    "    )\n",
    "model = KAdapterModel(config=kadapter_config, basemodel=basemodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that the KAdapter-Model has been loaded with a single Adapter, we can pretrain this Adapter to a specific task (e.g. RelationClassification).\n",
    "...\n",
    "After training, we can save the pretrained adapter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d7eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_adapter = model.adapters[0]\n",
    "pretrained_adapter.save_pretrained('./save/pretrained_adapter')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do this with each individual adapter.\n",
    "In the end, combine them all in the KAdapter architecture, injecting the Adapter knowledge into the basemodel.\n",
    "At this point, the basemodel and the head can be trained on the actual task."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_adapter = AutoModel.from_pretrained('./save/pretrained_adapter')\n",
    "# ... Load an arbitrary amount of pretrained adapters\n",
    "\n",
    "# Create head from config\n",
    "head_config = KAdapterConcatHeadConfig(n_adapters=1, hidden_size=loaded_adapter.config.hidden_size)\n",
    "# Create a partial kadapter config\n",
    "partial_kadapter_config = KAdapterConfig.from_adapter_configs(\n",
    "    head=head_config,\n",
    "    freeze_basemodel=False\n",
    ")\n",
    "\n",
    "# Create the K-Adapter Model by partly loading pretrained models and loading model architectures from configs.\n",
    "model = KAdapterModel.from_adapters_pretrained('roberta-base', ['./save/pretrained_adapter'], None,\n",
    "                                               config=partial_kadapter_config,\n",
    "                                               output_hidden_states=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the knowledge-injected model on a certain dataset and save it!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
